{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7836a9a-3170-454a-a28d-d4569abbc014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "\n",
    "# Step 1: Load the raw subject details file\n",
    "file_path = \"subject_details_new_model.txt\"  # Change path if needed\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Step 2: Parse each subject block into structured dictionary\n",
    "def parse_subjects(text):\n",
    "    subjects = []\n",
    "    entries = text.strip().split('\\n\\n')  # Each subject is separated by blank lines\n",
    "\n",
    "    for entry in entries:\n",
    "        subject = defaultdict(list)\n",
    "        lines = entry.strip().split('\\n')\n",
    "        context = None\n",
    "\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"Subject Name:\"):\n",
    "                subject[\"name\"] = line.replace(\"Subject Name:\", \"\").strip()\n",
    "            elif line.startswith(\"Subject Code:\"):\n",
    "                subject[\"code\"] = line.replace(\"Subject Code:\", \"\").strip().replace(\" \", \"\")\n",
    "            elif line.startswith(\"Pre-requisite:\"):\n",
    "                prereq = line.replace(\"Pre-requisite:\", \"\").strip()\n",
    "                subject[\"prerequisites\"] = []\n",
    "                context = \"prerequisites\"\n",
    "                if prereq and prereq.lower() != \"no\" and not prereq.startswith(\"- \"):\n",
    "                    subject[\"prerequisites\"].append(prereq)  \n",
    "            elif line.startswith(\"- \") and context == \"prerequisites\":\n",
    "                item = line.strip(\"- \").strip()\n",
    "                if item:  # avoid empty string\n",
    "                    subject[\"prerequisites\"].append(item)\n",
    "            elif line.startswith(\"Co-requisite:\"):\n",
    "                coreq = line.replace(\"Co-requisite:\", \"\").strip()\n",
    "                subject[\"corequisites\"] = [] if coreq.lower() == \"no\" else [coreq]\n",
    "            elif line.startswith(\"Credit point:\"):\n",
    "                subject[\"point\"] = line.replace(\"Credit point:\", \"\").strip()\n",
    "            elif line.startswith(\"Restrictions:\"):\n",
    "                subject[\"retrictions\"] = []\n",
    "                context = \"retrictions\"\n",
    "            elif line.startswith(\"Assumed Knowledge:\"):\n",
    "                subject[\"knowledges\"] = []\n",
    "                context = \"knowledges\"      \n",
    "            elif line.startswith(\"Teaching Periods:\"):\n",
    "                subject[\"teaching_periods\"] = []\n",
    "                context = \"teaching\"\n",
    "            elif line.startswith(\"Subject Content:\") or line.startswith(\"Subject content:\"):\n",
    "                subject[\"contents\"] = []\n",
    "                context = \"contents\"\n",
    "            elif line.startswith(\"Learning outcomes:\") or line.startswith(\"Learning Outcomes:\"):\n",
    "                subject[\"outcomes\"] = []\n",
    "                context = \"outcomes\"\n",
    "            elif line.startswith(\"- \"):\n",
    "                if context == \"teaching\":\n",
    "                    subject[\"teaching_periods\"].append(line.strip(\"- \").strip())\n",
    "                elif context == \"contents\":\n",
    "                    subject[\"contents\"].append(line.strip(\"- \").strip())\n",
    "                elif context == \"outcomes\":\n",
    "                    subject[\"outcomes\"].append(line.strip(\"- \").strip())\n",
    "                elif context == \"knowledges\":\n",
    "                    subject[\"knowledges\"].append(line.strip(\"- \").strip())\n",
    "                elif context == \"retrictions\":\n",
    "                    subject[\"retrictions\"].append(line.strip(\"- \").strip())\n",
    "\n",
    "        if \"code\" in subject:\n",
    "            subjects.append(subject)\n",
    "\n",
    "    return subjects\n",
    "\n",
    "subjects_data = parse_subjects(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd23018b-f5dd-4d26-92a8-fa3964b616a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[defaultdict(list,\n",
       "             {'name': 'Programming for Data Science',\n",
       "              'code': 'COMP7024',\n",
       "              'teaching_periods': ['Spring 2024',\n",
       "               'Quarter 1 2025',\n",
       "               'Autumn 2025',\n",
       "               'Spring 2025'],\n",
       "              'prerequisites': [],\n",
       "              'point': '10',\n",
       "              'contents': ['Introduction to R and R-Studio',\n",
       "               'Data Types, Variables, Expressions, and Data Structures',\n",
       "               'Input and Output',\n",
       "               'Control Structures: Loops, Conditional Expressions, and Functions',\n",
       "               'Simulation techniques',\n",
       "               'Object-oriented programming in R',\n",
       "               'Introduction to SQL',\n",
       "               'Using Markdown for reporting'],\n",
       "              'outcomes': ['Use Excel to manage and manipulate data.',\n",
       "               'Extract, transform and load data using R and R-Studio; including reading and writing data files.',\n",
       "               'Create complex R programs to conduct Data Science tasks.',\n",
       "               'Use basic SQL to access databases.',\n",
       "               'Apply simulation techniques to Data Science tasks.',\n",
       "               'Create reports using Markdown and R-Markdown.']}),\n",
       " defaultdict(list,\n",
       "             {'name': 'The Nature of Data',\n",
       "              'code': 'MATH7016',\n",
       "              'point': '10',\n",
       "              'teaching_periods': ['Spring 2024',\n",
       "               'Autumn 2025',\n",
       "               'Quarter 2 2025',\n",
       "               'Spring 2025',\n",
       "               'Quarter 4 2025'],\n",
       "              'prerequisites': [],\n",
       "              'retrictions': ['Students must be enrolled in a postgraduate program.'],\n",
       "              'knowledges': ['Undergraduate degree with some statistical content (1 subject) is useful.'],\n",
       "              'contents': ['The Types, Description and Exploration of Data',\n",
       "               'Collecting Good Data',\n",
       "               'Probability Theory',\n",
       "               'Computer assisted Estimation and Inference',\n",
       "               'Linear Modelling',\n",
       "               'Large Samples and Normal Theory',\n",
       "               'Common Statistical Mistakes'],\n",
       "              'outcomes': ['Describe types of data and the relevance to real world examples',\n",
       "               'Design data collection strategies that provide unbiased and reliable data']}),\n",
       " defaultdict(list,\n",
       "             {'name': 'Big Data',\n",
       "              'code': 'COMP7003',\n",
       "              'point': '10',\n",
       "              'teaching_periods': ['Autumn 2025'],\n",
       "              'prerequisites': [],\n",
       "              'knowledges': ['It is expected that students enrolled in this subject should have basic programming skills in any programming language and working knowledge in elementary probability and statistics, including the concepts of random variables, basic probability distributions, expectations, mean and variance.'],\n",
       "              'contents': ['Foundations and recent trends of big data',\n",
       "               'Parallel database management systems',\n",
       "               'Data parallelism and the MapReduce framework',\n",
       "               'NoSQL databases and cloud services',\n",
       "               'Data processing and manipulation for big data analysis'],\n",
       "              'outcomes': ['Explain the major trends in technology, business, and science behind big data',\n",
       "               'Analyse and compare a selection of major big data management techniques in use today, including parallel databases, NoSQL, MapReduce, cloud services']}),\n",
       " defaultdict(list,\n",
       "             {'name': 'Visualisation',\n",
       "              'code': 'COMP7016',\n",
       "              'point': '10',\n",
       "              'teaching_periods': ['Quarter 3 2024',\n",
       "               'Autumn 2025',\n",
       "               'Quarter 3 2025'],\n",
       "              'prerequisites': ['MATH 7016'],\n",
       "              'retrictions': ['Students must be enrolled in a postgraduate program.'],\n",
       "              'knowledges': ['Familiarity with computer software programs, such as Microsoft Office.'],\n",
       "              'contents': ['Information visualisation including main concepts and overview',\n",
       "               'Visual mappings and visual perception',\n",
       "               'Trees and graphs visualisation',\n",
       "               'Multi-dimensional data visualisation',\n",
       "               'Spatio-temporal data visualisation',\n",
       "               'Interaction',\n",
       "               'Using visualisation and tools to understand data',\n",
       "               'Visual Analytics'],\n",
       "              'outcomes': ['Explain the purpose of information visualisation',\n",
       "               'Identify strengths, limitations and opportunity of visualisation techniques',\n",
       "               'Evaluate common visualisation techniques for relational data, multi-dimensional data and spatio-temporal data',\n",
       "               'Analyse interaction methods in visualisation',\n",
       "               'Apply common visualisation tools for data analysis',\n",
       "               'Evaluate visual analytics technologies and tools for data analysis']}),\n",
       " defaultdict(list,\n",
       "             {'name': 'Data Science',\n",
       "              'code': 'COMP7006',\n",
       "              'point': '10',\n",
       "              'teaching_periods': ['Spring 2024',\n",
       "               'Quarter 4 2024',\n",
       "               'Spring 2025',\n",
       "               'Quarter 4 2025'],\n",
       "              'prerequisites': [],\n",
       "              'knowledges': ['Basic Statistics, Computer Programming.'],\n",
       "              'contents': ['Introduction to Data Science',\n",
       "               'The Map-Reduce paradigm for Big Data',\n",
       "               'Unsupervised Learning; Clustering, Dimension Reduction',\n",
       "               'Supervised Learning; Regression and Classification',\n",
       "               'Unstructured data',\n",
       "               'Visualisation and Visual Analytics'],\n",
       "              'outcomes': ['Describe the issues (computational and social) in data science',\n",
       "               'Show when and how to apply the MapReduce paradigm to solve data analytics problems',\n",
       "               'Select and apply appropriate Machine learning and statistical algorithms to extract information from data',\n",
       "               'Evaluate and interpret the utility of information found using Data Science']}),\n",
       " defaultdict(list,\n",
       "             {'name': 'Advanced Statistical Methods',\n",
       "              'code': 'MATH7002',\n",
       "              'point': '10',\n",
       "              'teaching_periods': ['Spring 2024', 'Spring 2025'],\n",
       "              'prerequisites': ['MATH 7012', 'MATH 7016'],\n",
       "              'corequisites': ['COMP 7006'],\n",
       "              'retrictions': ['Students must be enrolled in a postgraduate program.'],\n",
       "              'contents': ['Review of Probability Theory and Likelihood',\n",
       "               'Density Estimation',\n",
       "               'Maximum Likelihood and EM algorithm',\n",
       "               'Jack-knife, Bootstrap and Cross-validation',\n",
       "               'Introduction to Bayesian Methods',\n",
       "               'Markovian and Hidden Markov Models'],\n",
       "              'outcomes': ['Use density estimation to model continuous data.',\n",
       "               'Apply the EM algorithm (Expectation-Maximisation Algorithm) to maximise complex likelihood functions.',\n",
       "               'Evaluate models using computational techniques',\n",
       "               'Analyse data using Bayesian statistical models and MCMC (Markov-Chain Monte Carlo)']}),\n",
       " defaultdict(list,\n",
       "             {'name': 'Predictive Analytics',\n",
       "              'code': 'COMP7023',\n",
       "              'teaching_periods': ['Spring 2024', 'Spring 2025'],\n",
       "              'prerequisites': [],\n",
       "              'point': '10',\n",
       "              'contents': ['The information age has allowed business and science to take advantage of the vast amount of available data for predicting outcomes and estimating trends, to make informed decisions.',\n",
       "               'Machine learning is the process of allowing a computer to learn from data, which at its heart is used in making these important decisions.',\n",
       "               'Students will use the Python programming language throughout this subject.'],\n",
       "              'outcomes': ['Students will gain knowledge and practice required to implement and effectively use predictive models such as Neural Networks and Support Vector Machines.',\n",
       "               'Students will have opportunity to investigate state-of-the-art.']}),\n",
       " defaultdict(list,\n",
       "             {'name': 'Postgraduate Project A',\n",
       "              'code': 'INFO7016',\n",
       "              'point': '10',\n",
       "              'teaching_periods': ['Term 2 2024',\n",
       "               'Spring 2024',\n",
       "               'Autumn 2025',\n",
       "               'Spring 2025'],\n",
       "              'retrictions': ['Students must be enrolled in a postgraduate program and have successfully completed 60 credit points of postgraduate subjects.'],\n",
       "              'contents': ['Questioning: develop research question(s) or hypotheses',\n",
       "               'Problem identification: identify A Problem in A relevant field'],\n",
       "              'outcomes': ['Critically analyse the relevant literature to identify potential research problems in the fields of ICT, DS, AI, and Mathematics.',\n",
       "               'Generate research questions and hypothesis based on the literature review and the changing landscape.']}),\n",
       " defaultdict(list,\n",
       "             {'name': 'Social Media Intelligence',\n",
       "              'code': 'COMP7025',\n",
       "              'point': '10',\n",
       "              'teaching_periods': ['Autumn 2025', 'Quarter 2 2025'],\n",
       "              'prerequisites': [],\n",
       "              'knowledges': ['Basic algebra and computing skills'],\n",
       "              'contents': ['Graph theory and social networks',\n",
       "               'Introduction to Game theory',\n",
       "               'Information networks and the Web',\n",
       "               'Network population models',\n",
       "               'Network structural models'],\n",
       "              'outcomes': ['Identify and describe properties of social media networks.',\n",
       "               'Compute graph statistics from given social media networks.',\n",
       "               'Analyse simple games and describe their connection to social media networks.',\n",
       "               'Compute and interpret centrality scores over social media networks.',\n",
       "               'Generate and identify small world networks.',\n",
       "               'Use a computer to assist in the analysis of large scale social networks.']}),\n",
       " defaultdict(list,\n",
       "             {'name': 'Advanced Machine Learning',\n",
       "              'code': 'INFO7001',\n",
       "              'point': '10',\n",
       "              'teaching_periods': ['Spring 2024', 'Spring 2025'],\n",
       "              'prerequisites': ['COMP 7024'],\n",
       "              'retrictions': ['Students must be enrolled in a postgraduate program.'],\n",
       "              'knowledges': ['Fundamentals of computer programming and basic linear algebra.'],\n",
       "              'contents': ['Introduction to Advanced Machine Learning',\n",
       "               'Deep Learning',\n",
       "               'Reinforcement Learning'],\n",
       "              'outcomes': ['Describe appropriate machine learning methods for given problems.',\n",
       "               'Fit modern machine learning models to data.',\n",
       "               'Make predictions based on a fitted machine learning model.',\n",
       "               'Analyse data based on a fitted machine learning model.',\n",
       "               'Evaluate the utility of a machine learning method for given data.']}),\n",
       " defaultdict(list,\n",
       "             {'name': 'Postgraduate Project B',\n",
       "              'code': 'INFO7017',\n",
       "              'point': '10',\n",
       "              'teaching_periods': ['Spring 2024',\n",
       "               'Autumn 2025',\n",
       "               'Spring 2025'],\n",
       "              'corequisites': ['INFO 7016'],\n",
       "              'knowledges': ['Fundamentals of software or information systems management, Knowledge in research methodology and Skills in literature review and oral presentation.'],\n",
       "              'contents': ['Literature review: further review and appraise the current literature related to the study topic.',\n",
       "               'Implementation of research methodology: the research plan and methodology that have been established in Postgraduate Project A are implemented in this subject. Students may carry out the experimental work or numerical simulations or theoretical analysis or field studies.',\n",
       "               'Analysis and discussion: conduct detailed quantitative and qualitative analyses of the data collected and discuss the results.',\n",
       "               'Reporting: produce a complete dissertation and present the final findings clearly stating the student’s own original contribution to the study topic.'],\n",
       "              'outcomes': ['Conduct continuous review of existing literature in the fields of ICT, DS, AI, and Mathematics to identify the relevance to the proposed research project.',\n",
       "               'Execute a prepared research plan using appropriate methodologies.',\n",
       "               'Evaluate research findings against intended project outcomes.',\n",
       "               'Articulate research results in professional/formal and informal formats and contexts.',\n",
       "               'Apply self-management skills in executing research in computing contexts and oral presentation.',\n",
       "               'Demonstrate research ethics in synthesising complex information from a range of sources and referencing appropriately.']}),\n",
       " defaultdict(list,\n",
       "             {'name': 'Probablistic Graphical Models',\n",
       "              'code': 'MATH7017',\n",
       "              'point': '10',\n",
       "              'teaching_periods': ['Autumn 2025'],\n",
       "              'prerequisites': ['MATH 7016'],\n",
       "              'knowledges': ['Probability, Linear Algebra, Basic Programming.'],\n",
       "              'contents': ['Network representation and graphical models',\n",
       "               'Probabilistic models and entropy',\n",
       "               'Inference in graphical models',\n",
       "               'Learning graphical models'],\n",
       "              'outcomes': ['Manually construct probabilistic models for specific data.',\n",
       "               'Automatically construct probabilistic models by learning from data.',\n",
       "               'Use the models to make decisions under uncertainty.',\n",
       "               'Accurately represent a probabilistic model using a graphical representation.']})]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d8112a9-7954-4174-b015-23ace39af7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "URI = \"neo4j://127.0.0.1:7687\"   # or \"neo4j://localhost:7687\"\n",
    "AUTH = (\"neo4j\", \"datvip01\")\n",
    "\n",
    "driver = GraphDatabase.driver(URI, auth=AUTH)\n",
    "driver.verify_connectivity()\n",
    "print(\"Connected!\")\n",
    "# driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b945802e-2b06-49cd-a177-598fffb06d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    }
   ],
   "source": [
    "with driver.session(database=\"neo4j\") as s:      # << specify database here\n",
    "    print(s.run(\"MATCH (n) RETURN count(n) AS n\").single()[\"n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3b73702-9d17-4118-8c0e-79211ff829a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared rows: 12\n",
      "{'code': 'COMP7024', 'name': 'Programming for Data Science', 'credits': '10', 'coordinator': 'Chng Wei Lau', 'periods': ['Spring 2024', 'Quarter 1 2025', 'Autumn 2025', 'Spring 2025'], 'topics': ['Introduction to R and R-Studio', 'Data Types, Variables, Expressions, and Data Structures', 'Input and Output', 'Control Structures: Loops, Conditional Expressions, and Functions', 'Simulation techniques', 'Object-oriented programming in R', 'Introduction to SQL', 'Using Markdown for reporting'], 'outcomes': ['Use Excel to manage and manipulate data.', 'Extract, transform and load data using R and R-Studio; including reading and writing data files.', 'Create complex R programs to conduct Data Science tasks.', 'Use basic SQL to access databases.', 'Apply simulation techniques to Data Science tasks.', 'Create reports using Markdown and R-Markdown.'], 'assumed': [], 'restrictions': [], 'prereq_raw': [], 'coreq_raw': []}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) Re-split raw blocks so we can grab coordinator from each block\n",
    "raw_text = Path(\"subject_details_new_model.txt\").read_text(encoding=\"utf-8\")\n",
    "raw_blocks = [b.strip() for b in raw_text.split(\"\\n\\n\") if b.strip()]\n",
    "\n",
    "# Build a map from code->coordinator by regex on raw blocks\n",
    "code_to_coord = {}\n",
    "for b in raw_blocks:\n",
    "    m_code = re.search(r\"Subject Code:\\s*([^\\n]+)\", b)\n",
    "    m_coord = re.search(r\"Coordinator:\\s*([^\\n]+)\", b)\n",
    "    if m_code:\n",
    "        code = re.sub(r\"\\s+\", \"\", m_code.group(1)).upper()  # remove spaces, upper\n",
    "        coord = m_coord.group(1).strip() if m_coord else None\n",
    "        code_to_coord[code] = coord\n",
    "\n",
    "def norm_code(s):\n",
    "    return re.sub(r\"\\s+\", \"\", s).upper() if s else None\n",
    "\n",
    "def norm_txt(s):\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip() if s else None\n",
    "\n",
    "def norm_list(lst):\n",
    "    if not lst: return []\n",
    "    clean = [norm_txt(x) for x in lst if norm_txt(x)]\n",
    "    # keep order but unique\n",
    "    seen, out = set(), []\n",
    "    for x in clean:\n",
    "        if x not in seen:\n",
    "            seen.add(x); out.append(x)\n",
    "    return out\n",
    "\n",
    "rows = []\n",
    "for subj in subjects_data:\n",
    "    code = norm_code(subj.get(\"code\"))\n",
    "    if not code:\n",
    "        continue\n",
    "\n",
    "    row = {\n",
    "        \"code\": code,\n",
    "        \"name\": norm_txt(subj.get(\"name\")),\n",
    "        \"credits\": norm_txt(subj.get(\"point\")),\n",
    "        \"coordinator\": norm_txt(code_to_coord.get(code)),  # from raw block map\n",
    "        \"periods\": norm_list(subj.get(\"teaching_periods\")),\n",
    "        \"topics\": norm_list(subj.get(\"contents\")),\n",
    "        \"outcomes\": norm_list(subj.get(\"outcomes\")),\n",
    "        \"assumed\": norm_list(subj.get(\"knowledges\")),\n",
    "        \"restrictions\": norm_list(subj.get(\"retrictions\")),\n",
    "        \"prereq_raw\": norm_list(subj.get(\"prerequisites\")),\n",
    "        \"coreq_raw\": norm_list(subj.get(\"corequisites\")),\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "print(\"Prepared rows:\", len(rows))\n",
    "print(rows[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5a77fde-a5e6-4650-8c99-6d1807fa4797",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'code': 'COMP7024',\n",
       "  'name': 'Programming for Data Science',\n",
       "  'credits': '10',\n",
       "  'coordinator': 'Chng Wei Lau',\n",
       "  'periods': ['Spring 2024', 'Quarter 1 2025', 'Autumn 2025', 'Spring 2025'],\n",
       "  'topics': ['Introduction to R and R-Studio',\n",
       "   'Data Types, Variables, Expressions, and Data Structures',\n",
       "   'Input and Output',\n",
       "   'Control Structures: Loops, Conditional Expressions, and Functions',\n",
       "   'Simulation techniques',\n",
       "   'Object-oriented programming in R',\n",
       "   'Introduction to SQL',\n",
       "   'Using Markdown for reporting'],\n",
       "  'outcomes': ['Use Excel to manage and manipulate data.',\n",
       "   'Extract, transform and load data using R and R-Studio; including reading and writing data files.',\n",
       "   'Create complex R programs to conduct Data Science tasks.',\n",
       "   'Use basic SQL to access databases.',\n",
       "   'Apply simulation techniques to Data Science tasks.',\n",
       "   'Create reports using Markdown and R-Markdown.'],\n",
       "  'assumed': [],\n",
       "  'restrictions': [],\n",
       "  'prereq_raw': [],\n",
       "  'coreq_raw': []},\n",
       " {'code': 'MATH7016',\n",
       "  'name': 'The Nature of Data',\n",
       "  'credits': '10',\n",
       "  'coordinator': 'Gizem Intepe',\n",
       "  'periods': ['Spring 2024',\n",
       "   'Autumn 2025',\n",
       "   'Quarter 2 2025',\n",
       "   'Spring 2025',\n",
       "   'Quarter 4 2025'],\n",
       "  'topics': ['The Types, Description and Exploration of Data',\n",
       "   'Collecting Good Data',\n",
       "   'Probability Theory',\n",
       "   'Computer assisted Estimation and Inference',\n",
       "   'Linear Modelling',\n",
       "   'Large Samples and Normal Theory',\n",
       "   'Common Statistical Mistakes'],\n",
       "  'outcomes': ['Describe types of data and the relevance to real world examples',\n",
       "   'Design data collection strategies that provide unbiased and reliable data'],\n",
       "  'assumed': ['Undergraduate degree with some statistical content (1 subject) is useful.'],\n",
       "  'restrictions': ['Students must be enrolled in a postgraduate program.'],\n",
       "  'prereq_raw': [],\n",
       "  'coreq_raw': []},\n",
       " {'code': 'COMP7003',\n",
       "  'name': 'Big Data',\n",
       "  'credits': '10',\n",
       "  'coordinator': 'Yi Guo',\n",
       "  'periods': ['Autumn 2025'],\n",
       "  'topics': ['Foundations and recent trends of big data',\n",
       "   'Parallel database management systems',\n",
       "   'Data parallelism and the MapReduce framework',\n",
       "   'NoSQL databases and cloud services',\n",
       "   'Data processing and manipulation for big data analysis'],\n",
       "  'outcomes': ['Explain the major trends in technology, business, and science behind big data',\n",
       "   'Analyse and compare a selection of major big data management techniques in use today, including parallel databases, NoSQL, MapReduce, cloud services'],\n",
       "  'assumed': ['It is expected that students enrolled in this subject should have basic programming skills in any programming language and working knowledge in elementary probability and statistics, including the concepts of random variables, basic probability distributions, expectations, mean and variance.'],\n",
       "  'restrictions': [],\n",
       "  'prereq_raw': [],\n",
       "  'coreq_raw': []},\n",
       " {'code': 'COMP7016',\n",
       "  'name': 'Visualisation',\n",
       "  'credits': '10',\n",
       "  'coordinator': 'Quang Vinh Nguyen',\n",
       "  'periods': ['Quarter 3 2024', 'Autumn 2025', 'Quarter 3 2025'],\n",
       "  'topics': ['Information visualisation including main concepts and overview',\n",
       "   'Visual mappings and visual perception',\n",
       "   'Trees and graphs visualisation',\n",
       "   'Multi-dimensional data visualisation',\n",
       "   'Spatio-temporal data visualisation',\n",
       "   'Interaction',\n",
       "   'Using visualisation and tools to understand data',\n",
       "   'Visual Analytics'],\n",
       "  'outcomes': ['Explain the purpose of information visualisation',\n",
       "   'Identify strengths, limitations and opportunity of visualisation techniques',\n",
       "   'Evaluate common visualisation techniques for relational data, multi-dimensional data and spatio-temporal data',\n",
       "   'Analyse interaction methods in visualisation',\n",
       "   'Apply common visualisation tools for data analysis',\n",
       "   'Evaluate visual analytics technologies and tools for data analysis'],\n",
       "  'assumed': ['Familiarity with computer software programs, such as Microsoft Office.'],\n",
       "  'restrictions': ['Students must be enrolled in a postgraduate program.'],\n",
       "  'prereq_raw': ['MATH 7016'],\n",
       "  'coreq_raw': []},\n",
       " {'code': 'COMP7006',\n",
       "  'name': 'Data Science',\n",
       "  'credits': '10',\n",
       "  'coordinator': 'Liwan Liyanage',\n",
       "  'periods': ['Spring 2024',\n",
       "   'Quarter 4 2024',\n",
       "   'Spring 2025',\n",
       "   'Quarter 4 2025'],\n",
       "  'topics': ['Introduction to Data Science',\n",
       "   'The Map-Reduce paradigm for Big Data',\n",
       "   'Unsupervised Learning; Clustering, Dimension Reduction',\n",
       "   'Supervised Learning; Regression and Classification',\n",
       "   'Unstructured data',\n",
       "   'Visualisation and Visual Analytics'],\n",
       "  'outcomes': ['Describe the issues (computational and social) in data science',\n",
       "   'Show when and how to apply the MapReduce paradigm to solve data analytics problems',\n",
       "   'Select and apply appropriate Machine learning and statistical algorithms to extract information from data',\n",
       "   'Evaluate and interpret the utility of information found using Data Science'],\n",
       "  'assumed': ['Basic Statistics, Computer Programming.'],\n",
       "  'restrictions': [],\n",
       "  'prereq_raw': [],\n",
       "  'coreq_raw': []},\n",
       " {'code': 'MATH7002',\n",
       "  'name': 'Advanced Statistical Methods',\n",
       "  'credits': '10',\n",
       "  'coordinator': 'Yi Guo',\n",
       "  'periods': ['Spring 2024', 'Spring 2025'],\n",
       "  'topics': ['Review of Probability Theory and Likelihood',\n",
       "   'Density Estimation',\n",
       "   'Maximum Likelihood and EM algorithm',\n",
       "   'Jack-knife, Bootstrap and Cross-validation',\n",
       "   'Introduction to Bayesian Methods',\n",
       "   'Markovian and Hidden Markov Models'],\n",
       "  'outcomes': ['Use density estimation to model continuous data.',\n",
       "   'Apply the EM algorithm (Expectation-Maximisation Algorithm) to maximise complex likelihood functions.',\n",
       "   'Evaluate models using computational techniques',\n",
       "   'Analyse data using Bayesian statistical models and MCMC (Markov-Chain Monte Carlo)'],\n",
       "  'assumed': [],\n",
       "  'restrictions': ['Students must be enrolled in a postgraduate program.'],\n",
       "  'prereq_raw': ['MATH 7012', 'MATH 7016'],\n",
       "  'coreq_raw': ['COMP 7006']},\n",
       " {'code': 'COMP7023',\n",
       "  'name': 'Predictive Analytics',\n",
       "  'credits': '10',\n",
       "  'coordinator': 'Rosalind Wang',\n",
       "  'periods': ['Spring 2024', 'Spring 2025'],\n",
       "  'topics': ['The information age has allowed business and science to take advantage of the vast amount of available data for predicting outcomes and estimating trends, to make informed decisions.',\n",
       "   'Machine learning is the process of allowing a computer to learn from data, which at its heart is used in making these important decisions.',\n",
       "   'Students will use the Python programming language throughout this subject.'],\n",
       "  'outcomes': ['Students will gain knowledge and practice required to implement and effectively use predictive models such as Neural Networks and Support Vector Machines.',\n",
       "   'Students will have opportunity to investigate state-of-the-art.'],\n",
       "  'assumed': [],\n",
       "  'restrictions': [],\n",
       "  'prereq_raw': [],\n",
       "  'coreq_raw': []},\n",
       " {'code': 'INFO7016',\n",
       "  'name': 'Postgraduate Project A',\n",
       "  'credits': '10',\n",
       "  'coordinator': 'Jianhua Yang',\n",
       "  'periods': ['Term 2 2024', 'Spring 2024', 'Autumn 2025', 'Spring 2025'],\n",
       "  'topics': ['Questioning: develop research question(s) or hypotheses',\n",
       "   'Problem identification: identify A Problem in A relevant field'],\n",
       "  'outcomes': ['Critically analyse the relevant literature to identify potential research problems in the fields of ICT, DS, AI, and Mathematics.',\n",
       "   'Generate research questions and hypothesis based on the literature review and the changing landscape.'],\n",
       "  'assumed': [],\n",
       "  'restrictions': ['Students must be enrolled in a postgraduate program and have successfully completed 60 credit points of postgraduate subjects.'],\n",
       "  'prereq_raw': [],\n",
       "  'coreq_raw': []},\n",
       " {'code': 'COMP7025',\n",
       "  'name': 'Social Media Intelligence',\n",
       "  'credits': '10',\n",
       "  'coordinator': 'Laurence Park',\n",
       "  'periods': ['Autumn 2025', 'Quarter 2 2025'],\n",
       "  'topics': ['Graph theory and social networks',\n",
       "   'Introduction to Game theory',\n",
       "   'Information networks and the Web',\n",
       "   'Network population models',\n",
       "   'Network structural models'],\n",
       "  'outcomes': ['Identify and describe properties of social media networks.',\n",
       "   'Compute graph statistics from given social media networks.',\n",
       "   'Analyse simple games and describe their connection to social media networks.',\n",
       "   'Compute and interpret centrality scores over social media networks.',\n",
       "   'Generate and identify small world networks.',\n",
       "   'Use a computer to assist in the analysis of large scale social networks.'],\n",
       "  'assumed': ['Basic algebra and computing skills'],\n",
       "  'restrictions': [],\n",
       "  'prereq_raw': [],\n",
       "  'coreq_raw': []},\n",
       " {'code': 'INFO7001',\n",
       "  'name': 'Advanced Machine Learning',\n",
       "  'credits': '10',\n",
       "  'coordinator': 'Oliver Obst',\n",
       "  'periods': ['Spring 2024', 'Spring 2025'],\n",
       "  'topics': ['Introduction to Advanced Machine Learning',\n",
       "   'Deep Learning',\n",
       "   'Reinforcement Learning'],\n",
       "  'outcomes': ['Describe appropriate machine learning methods for given problems.',\n",
       "   'Fit modern machine learning models to data.',\n",
       "   'Make predictions based on a fitted machine learning model.',\n",
       "   'Analyse data based on a fitted machine learning model.',\n",
       "   'Evaluate the utility of a machine learning method for given data.'],\n",
       "  'assumed': ['Fundamentals of computer programming and basic linear algebra.'],\n",
       "  'restrictions': ['Students must be enrolled in a postgraduate program.'],\n",
       "  'prereq_raw': ['COMP 7024'],\n",
       "  'coreq_raw': []},\n",
       " {'code': 'INFO7017',\n",
       "  'name': 'Postgraduate Project B',\n",
       "  'credits': '10',\n",
       "  'coordinator': 'Jianhua Yang',\n",
       "  'periods': ['Spring 2024', 'Autumn 2025', 'Spring 2025'],\n",
       "  'topics': ['Literature review: further review and appraise the current literature related to the study topic.',\n",
       "   'Implementation of research methodology: the research plan and methodology that have been established in Postgraduate Project A are implemented in this subject. Students may carry out the experimental work or numerical simulations or theoretical analysis or field studies.',\n",
       "   'Analysis and discussion: conduct detailed quantitative and qualitative analyses of the data collected and discuss the results.',\n",
       "   'Reporting: produce a complete dissertation and present the final findings clearly stating the student’s own original contribution to the study topic.'],\n",
       "  'outcomes': ['Conduct continuous review of existing literature in the fields of ICT, DS, AI, and Mathematics to identify the relevance to the proposed research project.',\n",
       "   'Execute a prepared research plan using appropriate methodologies.',\n",
       "   'Evaluate research findings against intended project outcomes.',\n",
       "   'Articulate research results in professional/formal and informal formats and contexts.',\n",
       "   'Apply self-management skills in executing research in computing contexts and oral presentation.',\n",
       "   'Demonstrate research ethics in synthesising complex information from a range of sources and referencing appropriately.'],\n",
       "  'assumed': ['Fundamentals of software or information systems management, Knowledge in research methodology and Skills in literature review and oral presentation.'],\n",
       "  'restrictions': [],\n",
       "  'prereq_raw': [],\n",
       "  'coreq_raw': ['INFO 7016']},\n",
       " {'code': 'MATH7017',\n",
       "  'name': 'Probablistic Graphical Models',\n",
       "  'credits': '10',\n",
       "  'coordinator': 'Oliver Obst',\n",
       "  'periods': ['Autumn 2025'],\n",
       "  'topics': ['Network representation and graphical models',\n",
       "   'Probabilistic models and entropy',\n",
       "   'Inference in graphical models',\n",
       "   'Learning graphical models'],\n",
       "  'outcomes': ['Manually construct probabilistic models for specific data.',\n",
       "   'Automatically construct probabilistic models by learning from data.',\n",
       "   'Use the models to make decisions under uncertainty.',\n",
       "   'Accurately represent a probabilistic model using a graphical representation.'],\n",
       "  'assumed': ['Probability, Linear Algebra, Basic Programming.'],\n",
       "  'restrictions': [],\n",
       "  'prereq_raw': ['MATH 7016'],\n",
       "  'coreq_raw': []}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51fabeaa-9cd5-42f2-8ca8-30bb157eb4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingest complete.\n"
     ]
    }
   ],
   "source": [
    "q_ingest = \"\"\"\n",
    "UNWIND $rows AS r\n",
    "MERGE (s:Subject {code:r.code})\n",
    "  SET s.name = r.name,\n",
    "      s.credits = r.credits\n",
    "\n",
    "// Coordinator\n",
    "FOREACH (coord IN CASE WHEN r.coordinator IS NULL OR r.coordinator = \"\" THEN [] ELSE [r.coordinator] END |\n",
    "  MERGE (c:Coordinator {name: coord})\n",
    "  MERGE (s)-[:COORDINATED_BY]->(c)\n",
    ")\n",
    "\n",
    "// Teaching periods\n",
    "FOREACH (per IN coalesce(r.periods, []) |\n",
    "  MERGE (tp:TeachingPeriod {name: per})\n",
    "  MERGE (s)-[:OFFERED_IN]->(tp)\n",
    ")\n",
    "\n",
    "// Topics (subject content)\n",
    "FOREACH (t IN coalesce(r.topics, []) |\n",
    "  MERGE (topic:Topic {name: t})\n",
    "  MERGE (s)-[:COVERS]->(topic)\n",
    ")\n",
    "\n",
    "// Learning outcomes\n",
    "FOREACH (o IN coalesce(r.outcomes, []) |\n",
    "  MERGE (out:Outcome {description: o})\n",
    "  MERGE (s)-[:HAS_OUTCOME]->(out)\n",
    ")\n",
    "\n",
    "// Assumed knowledge\n",
    "FOREACH (ak IN coalesce(r.assumed, []) |\n",
    "  MERGE (k:AssumedKnowledge {name: ak})\n",
    "  MERGE (s)-[:ASSUMES]->(k)\n",
    ")\n",
    "\n",
    "// Restrictions (stored as nodes; keep simple label)\n",
    "FOREACH (res IN coalesce(r.restrictions, []) |\n",
    "  MERGE (rr:Restriction {name: res})\n",
    "  MERGE (s)-[:RESTRICTED_BY]->(rr)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as ses:\n",
    "    ses.run(q_ingest, rows=rows)\n",
    "\n",
    "print(\"Ingest complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b131a754-ec16-453e-b954-29c97f028ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prerequisites created: 7\n"
     ]
    }
   ],
   "source": [
    "# Extract possible subject codes from prereq text\n",
    "code_pat = re.compile(r\"[A-Z]{3,4}\\s*\\d{4}\")\n",
    "\n",
    "pairs = []  # (subject_code, prereq_code)\n",
    "for r in rows:\n",
    "    for raw in r[\"prereq_raw\"]:\n",
    "        for m in code_pat.findall(raw):\n",
    "            prereq = re.sub(r\"\\s+\", \"\", m).upper()\n",
    "            if prereq != r[\"code\"]:\n",
    "                pairs.append((r[\"code\"], prereq))\n",
    "\n",
    "for r in rows:\n",
    "    for raw in r[\"coreq_raw\"]:\n",
    "        for m in code_pat.findall(raw):\n",
    "            prereq = re.sub(r\"\\s+\", \"\", m).upper()\n",
    "            if prereq != r[\"code\"]:\n",
    "                pairs.append((r[\"code\"], prereq))\n",
    "\n",
    "# Keep unique pairs\n",
    "pairs = list({(a,b) for (a,b) in pairs})\n",
    "\n",
    "q_prereq = \"\"\"\n",
    "UNWIND $pairs AS pr\n",
    "MATCH (s:Subject {code: pr[0]})\n",
    "MATCH (p:Subject {code: pr[1]})\n",
    "MERGE (s)-[:REQUIRES]->(p)\n",
    "\"\"\"\n",
    "\n",
    "if pairs:\n",
    "    with driver.session() as ses:\n",
    "        ses.run(q_prereq, pairs=pairs)\n",
    "    print(\"Prerequisites created:\", len(pairs))\n",
    "else:\n",
    "    print(\"No subject-code prerequisites found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b2b7b53-3d6d-4eb8-8347-0a6f65197771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "neo4j_graph.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"720\"\n",
       "            src=\"neo4j_graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x26c2c4e44d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pip install pyvis\n",
    "from pyvis.network import Network\n",
    "from IPython.display import IFrame\n",
    "\n",
    "net = Network(height=\"700px\", width=\"100%\", directed=True, notebook=True)\n",
    "net.toggle_physics(True)\n",
    "\n",
    "with driver.session() as session:\n",
    "    result = session.run(\"\"\"\n",
    "    MATCH (s:Subject)\n",
    "    OPTIONAL MATCH (s)-[r]->(m)\n",
    "    RETURN s, r, m\n",
    "    LIMIT 200\n",
    "    \"\"\")\n",
    "\n",
    "    def node_id(n):  # stable id string\n",
    "        return f\"{list(n.labels)[0]}:{n.element_id}\"\n",
    "\n",
    "    for rec in result:\n",
    "        s, r, m = rec[\"s\"], rec[\"r\"], rec[\"m\"]\n",
    "        # add subject node\n",
    "        net.add_node(node_id(s),\n",
    "                     label=f\"{s.get('code')}\\n{s.get('name')}\",\n",
    "                     title=str(dict(s)),\n",
    "                     color=\"#ff9999\")\n",
    "        if m is not None and r is not None:\n",
    "            # add target node\n",
    "            lbls = list(m.labels)\n",
    "            label = m.get(\"name\") or m.get(\"description\") or \"/\".join(lbls)\n",
    "            color = {\"Coordinator\":\"#8ecae6\",\"TeachingPeriod\":\"#bde0fe\",\n",
    "                     \"Topic\":\"#caffbf\",\"Outcome\":\"#ffd6a5\",\n",
    "                     \"AssumedKnowledge\":\"#f1c0e8\"}.get(lbls[0], \"#dddddd\")\n",
    "            net.add_node(node_id(m), label=label, title=str(dict(m)), color=color)\n",
    "            # add edge\n",
    "            net.add_edge(node_id(s), node_id(m), label=r.type)\n",
    "\n",
    "# render to HTML and display\n",
    "net.show(\"neo4j_graph.html\")\n",
    "display(IFrame(\"neo4j_graph.html\", width=\"100%\", height=720))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dba0ad22-c0c6-447f-98c5-9febdb1c0b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_12480\\2883024933.py:11: LangChainDeprecationWarning: The class `Neo4jGraph` was deprecated in LangChain 0.3.8 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-neo4j package and should be used instead. To use it run `pip install -U :class:`~langchain-neo4j` and import as `from :class:`~langchain_neo4j import Neo4jGraph``.\n",
      "  graph = Neo4jGraph(\n"
     ]
    }
   ],
   "source": [
    "# pip install -q langchain langchain-community neo4j faiss-cpu\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=\"neo4j://127.0.0.1:7687\",\n",
    "    username=\"neo4j\",\n",
    "    password=\"datvip01\",\n",
    "    database=\"neo4j\", \n",
    "    refresh_schema=False,\n",
    ")\n",
    "\n",
    "# EXACT schema (only what exists!)\n",
    "schema = \"\"\"\n",
    "Nodes:\n",
    "  (:Subject {code, name, credits})\n",
    "  (:Coordinator {name})\n",
    "  (:TeachingPeriod {name})\n",
    "  (:Topic {name})\n",
    "  (:Outcome {description})\n",
    "  (:AssumedKnowledge {name})\n",
    "  (:Restriction {name})\n",
    "\n",
    "Relationships:\n",
    "  (:Subject)-[:COORDINATED_BY]->(:Coordinator)\n",
    "  (:Subject)-[:OFFERED_IN]->(:TeachingPeriod)\n",
    "  (:Subject)-[:COVERS]->(:Topic)\n",
    "  (:Subject)-[:HAS_OUTCOME]->(:Outcome)\n",
    "  (:Subject)-[:ASSUMES]->(:AssumedKnowledge)\n",
    "  (:Subject)-[:RESTRICTED_BY]->(:Restriction)\n",
    "  (:Subject)-[:REQUIRES]->(:Subject)   // exact spelling; DO NOT use REQUIREES or other variants\n",
    "\n",
    "General matching rules:\n",
    "- Teaching periods are nodes (:TeachingPeriod {name}), e.g., \"Autumn 2025\".\n",
    "- Season filtering must be case-insensitive and use STARTS WITH:\n",
    "  WHERE toLower(tp.name) STARTS WITH \"autumn\"  (similarly \"spring\")\n",
    "- Do NOT place inequality tests inside property maps { }.\n",
    "    MATCH (n:Label) WHERE n.prop <> \"X\"\n",
    "- Text matching on names/descriptions is partial and case-insensitive:\n",
    "  WHERE toLower(x.property) CONTAINS toLower($term)\n",
    "\n",
    "Prerequisites:\n",
    "- Use ONLY (:Subject)-[:REQUIRES]->(:Subject) to model prerequisites.\n",
    "- Example (list MATH7016 prerequisites consumers):\n",
    "  MATCH (s:Subject)-[:REQUIRES]->(p:Subject {code:\"MATH7016\"})\n",
    "  RETURN s.code AS subjectCode, s.name AS subjectName\n",
    "\n",
    "Exclusively/Intersection logic:\n",
    "- \"Exclusively in Autumn\": subject has >=1 Autumn offering AND no non-Autumn offerings.\n",
    "  Example:\n",
    "    MATCH (s:Subject)\n",
    "    WHERE EXISTS {\n",
    "      MATCH (s)-[:OFFERED_IN]->(tpA:TeachingPeriod)\n",
    "      WHERE toLower(tpA.name) STARTS WITH \"autumn\"\n",
    "    }\n",
    "    AND NOT EXISTS {\n",
    "      MATCH (s)-[:OFFERED_IN]->(tpN:TeachingPeriod)\n",
    "      WHERE NOT toLower(tpN.name) STARTS WITH \"autumn\"\n",
    "    }\n",
    "    RETURN s.code, s.name\n",
    "- \"In both Spring and Autumn\": require BOTH seasons:\n",
    "  - Aggregation:\n",
    "      MATCH (s)-[:OFFERED_IN]->(tp)\n",
    "      WITH s, collect(DISTINCT toLower(tp.name)) AS periods\n",
    "      WHERE any(p IN periods WHERE p STARTS WITH \"autumn\")\n",
    "        AND any(p IN periods WHERE p STARTS WITH \"spring\")\n",
    "      RETURN s.code, s.name\n",
    "  - Or two EXISTS subqueries as above.\n",
    "\n",
    "Discipline/area intent:\n",
    "- If the question asks for subjects in a discipline (e.g., \"Statistics\"), search semantic fields (Outcome.description and/or Topic.name), not code prefixes, unless explicitly requested.\n",
    "  Example:\n",
    "    MATCH (s:Subject)-[:HAS_OUTCOME]->(o:Outcome)\n",
    "    WHERE toLower(o.description) CONTAINS \"stat\"\n",
    "    RETURN DISTINCT s.code AS subjectCode, s.name AS subjectName\n",
    "\n",
    "Safety:\n",
    "- Only generate READ queries (MATCH/OPTIONAL MATCH/RETURN). No writes (CREATE/MERGE/DELETE/SET/DROP).\n",
    "\"\"\"\n",
    "\n",
    "cypher_prompt = PromptTemplate.from_template(\n",
    "\"\"\"You are a Cypher expert. Using ONLY this schema:\n",
    "\n",
    "{schema}\n",
    "\n",
    "Write a SINGLE read-only Cypher query that answers:\n",
    "{question}\n",
    "\n",
    "Constraints:\n",
    "- If filtering by period like \"Autumn 2025\", match (:TeachingPeriod {{name:\"Autumn 2025\"}}).\n",
    "- To return the coordinator, OPTIONAL MATCH to (:Coordinator) and return c.name as coordinator.\n",
    "- Return small, readable columns with aliases.\n",
    "- Do not use labels or properties not in the schema.\n",
    "- Only output the Cypher query (no explanation).\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "graph.schema = schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4a9814c-9198-4295-9ba1-ab7d35aba39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_12480\\3373669761.py:1: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"gemma3:12b\", temperature=0)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_12480\\3373669761.py:42: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  cypher_only = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"gemma3:12b\", temperature=0)\n",
    "\n",
    "# QA_PROMPT = PromptTemplate.from_template(\"\"\"\n",
    "# You are given rows from a Cypher query as JSON-like data.\n",
    "# If rows are empty, answer exactly: \"No matching results.\"\n",
    "# Otherwise, summarize concisely and list key fields (codes, names, coordinators, periods).\n",
    "\n",
    "# Rows:\n",
    "# {context}\n",
    "\n",
    "# User question:\n",
    "# {question}\n",
    "\n",
    "# Answer:\n",
    "# \"\"\")\n",
    "\n",
    "# chain = GraphCypherQAChain.from_llm(\n",
    "#     llm=llm,\n",
    "#     graph=graph,\n",
    "#     cypher_prompt=cypher_prompt.partial(schema=schema),\n",
    "#     validate_cypher=False,\n",
    "#     allow_dangerous_requests=True,   # use a read-only DB user\n",
    "#     return_intermediate_steps=True,  # we’ll read the query & rows\n",
    "#     return_direct=True,              # returns rows directly (skips QA)\n",
    "#     verbose=False\n",
    "# )\n",
    "\n",
    "# chain = GraphCypherQAChain.from_llm(\n",
    "#     llm=llm,\n",
    "#     graph=graph,\n",
    "#     cypher_prompt=cypher_prompt.partial(schema=schema),\n",
    "#     verbose=True,\n",
    "#     validate_cypher=False,\n",
    "#     allow_dangerous_requests=True, \n",
    "#     # qa_prompt=QA_PROMPT,\n",
    "#     return_intermediate_steps=True# use a read-only DB user for safety\n",
    "# )\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# 1) Build a tiny chain that ONLY generates Cypher\n",
    "cypher_only = LLMChain(\n",
    "    llm=llm,  # your Ollama LLM\n",
    "    prompt=cypher_prompt.partial(schema=schema)  # same prompt you already use\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "49b2ced3-e701-46b0-823f-03ff417ae297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -q langchain langchain-community neo4j faiss-cpu\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=\"neo4j://127.0.0.1:7687\",\n",
    "    username=\"neo4j\",\n",
    "    password=\"datvip01\",\n",
    "    database=\"neo4j\", \n",
    "    refresh_schema=False,\n",
    ")\n",
    "\n",
    "# EXACT schema (only what exists!)\n",
    "schema = \"\"\"\n",
    "Nodes:\n",
    "  (:Subject {code, name, credits})\n",
    "  (:Coordinator {name})\n",
    "  (:TeachingPeriod {name})\n",
    "  (:Topic {name})\n",
    "  (:Outcome {description})\n",
    "  (:AssumedKnowledge {name})\n",
    "  (:Restriction {name})\n",
    "\n",
    "Relationships:\n",
    "  (:Subject)-[:COORDINATED_BY]->(:Coordinator)\n",
    "  (:Subject)-[:OFFERED_IN]->(:TeachingPeriod)\n",
    "  (:Subject)-[:COVERS]->(:Topic)\n",
    "  (:Subject)-[:HAS_OUTCOME]->(:Outcome)\n",
    "  (:Subject)-[:ASSUMES]->(:AssumedKnowledge)\n",
    "  (:Subject)-[:RESTRICTED_BY]->(:Restriction)\n",
    "  (:Subject)-[:REQUIRES]->(:Subject)\n",
    "\n",
    "⚠️ STRICT SCHEMA — DO NOT DEVIATE ⚠️\n",
    "\n",
    "Cypher Generation Rules:\n",
    "\n",
    "1. Subject Code Format:\n",
    "   - Subject codes always follow the format: 4 uppercase letters + 4 digits (e.g., MATH1234).\n",
    "   - When returning results, always include distinct subject code and subject name only.\n",
    "   - When returning results, do not use function EXISTS.\n",
    "   - The only correct relationship about coordinator is MATCH (s:Subject)-[:COORDINATED_BY]->(c:Coordinator)\n",
    "   - Subject name can be used to filter (e.g., Predictive Analytics)\n",
    "\n",
    "2. Teaching Period Filtering:\n",
    "   - Teaching periods are nodes: (:TeachingPeriod {name}).\n",
    "   - When the question mentioned enroll or register the teaching period should be filtered.\n",
    "   - To filter by season, use case-insensitive matching:\n",
    "     ✅ Correct: WHERE toLower(tp.name) STARTS WITH \"autumn 2023\"\n",
    "     ❌ Incorrect: WHERE tp.name = \"Autumn 2023\"\n",
    "   - DO NOT USE NOT clause in teaching period filtering.\n",
    "\n",
    "3. Exclusive Offering Logic:\n",
    "   - To find subjects offered *only* in a specific season:\n",
    "     ✅ Use NOT EXISTS with curly braces:\n",
    "     ```\n",
    "     MATCH (s:Subject)-[:OFFERED_IN]->(tp:TeachingPeriod)\n",
    "     WHERE toLower(tp.name) STARTS WITH \"autumn\"\n",
    "     AND NOT EXISTS {\n",
    "       MATCH (s)-[:OFFERED_IN]->(tp2:TeachingPeriod)\n",
    "       WHERE NOT toLower(tp2.name) STARTS WITH \"autumn\"\n",
    "     }\n",
    "     RETURN s.code, s.name\n",
    "     ```\n",
    "     ❌ Do NOT use EXISTS(...) or NOT EXISTS(...)\n",
    "\n",
    "4. Subquery Syntax:\n",
    "   - Always use `{}` blocks for subqueries.\n",
    "   - NEVER use parentheses after EXISTS or NOT EXISTS.\n",
    "\n",
    "5. NOT Usage:\n",
    "   ✅ Correct: MATCH ... WHERE NOT toLower(tp.name) STARTS WITH \"spring\" AND NOT EXISTS { MATCH ... } RETURN ...\n",
    "   ❌ Incorrect: WHERE tp.name NOT STARTS WITH \"spring\"\n",
    "\n",
    "6. Prerequisite Relationship:\n",
    "- Only use: (subject:Subject)-[:REQUIRES]->(preqsub:Subject)\n",
    "- ❌ Do NOT use REQUIREES, REQUIRIES, REQUIRED_BY\n",
    "- Use NOT EXISTS to see if a subject have no prerequisite or not. Example: WHERE NOT EXISTS {MATCH (s)-[:REQUIRES]->(preqsub:Subject)}\n",
    "\n",
    "7. Discipline/area intent:\n",
    "- If the question asks for subjects in a discipline (e.g., \"Statistics\"), search semantic fields (Outcome.description and/or Topic.name),\n",
    "not code prefixes, unless explicitly requested.\n",
    "  Example:\n",
    "    MATCH ... WHERE toLower(o.description) CONTAINS \"...\" RETURN ...\n",
    "    or using\n",
    "    MATCH ... WHERE toLower(T.name) CONTAINS \"...\" RETURN ...\n",
    "\n",
    "8. Completed Subjects Logic:\n",
    "- Always use [] instead of () in where clause when using WHERE NOT s.code IN [...]\n",
    "- When the question mentions \"after finishing/completed\" a list of subjects:\n",
    "    * Exclude those completed subjects:\n",
    "    WHERE NOT s.code IN [...]\n",
    "    * Ensure prerequisites are satisfied:\n",
    "    AND NOT EXISTS {\n",
    "        MATCH (s)-[:REQUIRES]->(p:Subject)\n",
    "        WHERE NOT p.code IN [...]\n",
    "    }\n",
    "- This guarantees that all prerequisites of s are contained in the completed set.\n",
    "- ❌ Do NOT write queries that only check `s.code IN [...]` without the NOT EXISTS prerequisite logic.\n",
    "\n",
    "9. Restriction\n",
    "- If the question asks for subjects in a restriction (e.g., \"point\"), search semantic fields (Restriction.name),\n",
    "not code prefixes, unless explicitly requested.\n",
    "- Must return restriction name.\n",
    "  Example:\n",
    "    MATCH ... WHERE toLower(o.name) CONTAINS \"...\" RETURN ...\n",
    "\n",
    "10. Skill/assessment intent (e.g., \"presentations\", \"machine\", \"python\", \"learning\", \"programming\", \"project\"):\n",
    "- Never combine different graph patterns with OR (e.g., outcomes or topics) in a single branch.\n",
    "- Always search in both Outcome.description and Topic.name (case-insensitive, partial match).\n",
    "- To combine results from different relationships or node types (e.g., HAS_OUTCOME and COVERS), use two independent branches joined by UNION.\n",
    "- Each branch of the UNION must have its own RETURN clause and own WHERE clause, its own RETURN DISTINCT s.code, s.name.\n",
    "- The RETURN clauses must have identical columns (e.g., s.code AS subjectCode, s.name AS subjectName).\n",
    "- The search term must be treated as a whole phrase from the user query (e.g., \"machine learning\"), not split into individual words unless explicitly asked.\n",
    "- Always apply DISTINCT in each RETURN to remove duplicates.\n",
    "    Example the correct cypher:\n",
    "    \n",
    "    MATCH (s:Subject)-[:HAS_OUTCOME]->(o:Outcome)\n",
    "    WHERE toLower(o.description) CONTAINS \"python\"\n",
    "    RETURN DISTINCT s.code, s.name # must include\n",
    "    UNION\n",
    "    MATCH (s:Subject)-[:COVERS]->(t:Topic)\n",
    "    WHERE toLower(t.name) CONTAINS \"python\"\n",
    "    RETURN DISTINCT s.code, s.name\n",
    "\n",
    "11. Variable Definition Order:\n",
    "   - A variable (like `tp`) must be introduced in a MATCH clause before it is referenced in WHERE.\n",
    "   - Always place MATCH before any WHERE filters that reference its variables.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "cypher_prompt = PromptTemplate.from_template(\n",
    "\"\"\"You are a Cypher expert. Using ONLY this schema:\n",
    "\n",
    "{schema}\n",
    "\n",
    "Write a SINGLE read-only Cypher query that answers:\n",
    "{question}\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "graph.schema = schema\n",
    "\n",
    "llm = Ollama(model=\"gemma3:12b\", temperature=0)\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# 1) Build a tiny chain that ONLY generates Cypher\n",
    "cypher_only = LLMChain(\n",
    "    llm=llm,  # your Ollama LLM\n",
    "    prompt=cypher_prompt.partial(schema=schema)  # same prompt you already use\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a463acb-4503-4af0-a13a-ea2382cf86c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_cypher(cypher_text: str) -> str:\n",
    "    # Remove triple backticks and the 'cypher' label if present\n",
    "    cleaned = re.sub(r\"```[a-zA-Z]*\", \"\", cypher_text)  # removes ``` and ```cypher\n",
    "    cleaned = cleaned.replace(\"cypher\\n\", \"\")           # removes the prefix \"cypher\\n\"\n",
    "\n",
    "    cleaned = re.sub(r\"\\bREQUIREES\\b\", \"REQUIRES\", cleaned)\n",
    "    cleaned = re.sub(r\"\\bREQUIREEs\\b\", \"REQUIRES\", cleaned)\n",
    "    cleaned = re.sub(r\"\\bREQUIRIES\\b\", \"REQUIRES\", cleaned)\n",
    "    return cleaned.replace(\"```\", \"\").strip()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9ac5fbe0-bd15-4d1f-ab41-54709388aa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATCH (s:Subject)\n",
      "WHERE NOT s.code IN ['MATH7002', 'COMP7006', 'COMP7023']\n",
      "AND NOT EXISTS {\n",
      "  MATCH (s)-[:REQUIRES]->(p:Subject)\n",
      "  WHERE NOT p.code IN ['MATH7002', 'COMP7006', 'COMP7023']\n",
      "}\n",
      "AND EXISTS {\n",
      "  MATCH (s)-[:OFFERED_IN]->(tp:TeachingPeriod)\n",
      "  WHERE toLower(tp.name) STARTS WITH \"autumn\"\n",
      "}\n",
      "RETURN DISTINCT s.code, s.name\n",
      "Context:\n",
      "['COMP7003', 'Big Data']\n",
      "['INFO7016', 'Postgraduate Project A']\n",
      "['COMP7025', 'Social Media Intelligence']\n",
      "['COMP7024', 'Programming for Data Science']\n",
      "['MATH7016', 'The Nature of Data']\n"
     ]
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "After finishing MATH7002, COMP7006, and COMP7023, which subject can I take in the next Autumn semester?\n",
    "\"\"\"\n",
    "# answer = chain.invoke({\"query\": q})\n",
    "cypher_gen = cypher_only.invoke({\"question\": q})[\"text\"].strip()\n",
    "cleaned_cypher = clean_cypher(cypher_gen)\n",
    "print(cleaned_cypher)\n",
    "\n",
    "rows = graph.query(cleaned_cypher)\n",
    "print(\"Context:\")\n",
    "# Flatten and print only the values\n",
    "for row in rows:\n",
    "    a = list(row.values())\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aea278ae-fac2-428b-8372-51a208bc034f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "36e7d3ed-8e5f-45d3-99d4-56366a535097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "def get_query(query):\n",
    "    start = time.time()\n",
    "    cypher = cypher_only.invoke({\"question\": query})[\"text\"].strip()  \n",
    "    cypher_query = clean_cypher(cypher)\n",
    "    print(\"Generated Cypher:\\n\", cypher_query)\n",
    "\n",
    "    # Run the query\n",
    "    rows = graph.query(cypher_query)\n",
    "    \n",
    "    answers = []   # store all rows\n",
    "    for row in rows:\n",
    "        vals = list(row.values())\n",
    "        answers.append(vals)\n",
    "        print(vals)\n",
    "        \n",
    "    if not answers:\n",
    "        print(\"No results returned.\")\n",
    "        result = None\n",
    "    else:\n",
    "        result = answers\n",
    "\n",
    "    print(f\"Answered in {round(time.time() - start, 2)} seconds\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b627b787-7f82-4fac-bb70-5a110e045af9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Cypher:\n",
      " MATCH (s:Subject)-[:OFFERED_IN]->(tp:TeachingPeriod)\n",
      "WHERE toLower(tp.name) STARTS WITH \"spring\"\n",
      "AND NOT EXISTS {\n",
      "  MATCH (s)-[:REQUIRES]->(preqsub:Subject)\n",
      "}\n",
      "RETURN DISTINCT s.code\n",
      "['COMP7006']\n",
      "['COMP7023']\n",
      "['INFO7016']\n",
      "['COMP7024']\n",
      "['MATH7016']\n",
      "Answered in 280.61 seconds\n",
      "Generated Cypher:\n",
      " MATCH (s:Subject)\n",
      "WHERE NOT s.code IN ['MATH7016', 'COMP7024', 'COMP7003', 'COMP7016']\n",
      "  AND NOT EXISTS {\n",
      "    MATCH (s)-[:REQUIRES]->(p:Subject)\n",
      "    WHERE NOT p.code IN ['MATH7016', 'COMP7024', 'COMP7003', 'COMP7016']\n",
      "  }\n",
      "  AND toLower(tp.name) STARTS WITH \"spring\"\n",
      "  AND NOT EXISTS {\n",
      "    MATCH (s)-[:OFFERED_IN]->(tp:TeachingPeriod)\n",
      "    WHERE NOT toLower(tp.name) STARTS WITH \"spring\"\n",
      "  }\n",
      "RETURN DISTINCT s.code, s.name\n"
     ]
    },
    {
     "ename": "CypherSyntaxError",
     "evalue": "{code: Neo.ClientError.Statement.SyntaxError} {message: Variable `tp` not defined (line 7, column 15 (offset: 236))\r\n\"  AND toLower(tp.name) STARTS WITH \"spring\"\"\r\n               ^}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mGqlError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;31mGqlError\u001b[0m: {gql_status: 42N62} {gql_status_description: error: syntax error or access rule violation - variable not defined. Variable `tp` not defined.} {message: 42N62: Variable `tp` not defined.} {diagnostic_record: {'_classification': 'CLIENT_ERROR', '_position': {'offset': 236, 'column': 15, 'line': 7}, 'OPERATION': '', 'OPERATION_CODE': '0', 'CURRENT_SCHEMA': '/'}} {raw_classification: CLIENT_ERROR}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mCypherSyntaxError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion2_final.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Add model answers\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCypher Answer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: get_query(x))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Save results\u001b[39;00m\n\u001b[0;32m     10\u001b[0m df\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqa2_results.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4919\u001b[0m         func,\n\u001b[0;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[75], line 7\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion2_final.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Add model answers\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCypher Answer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: get_query(x))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Save results\u001b[39;00m\n\u001b[0;32m     10\u001b[0m df\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqa2_results.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[65], line 11\u001b[0m, in \u001b[0;36mget_query\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Cypher:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, cypher_query)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Run the query\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m rows \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mquery(cypher_query)\n\u001b[0;32m     13\u001b[0m answers \u001b[38;5;241m=\u001b[39m []   \u001b[38;5;66;03m# store all rows\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\graphs\\neo4j_graph.py:467\u001b[0m, in \u001b[0;36mNeo4jGraph.query\u001b[1;34m(self, query, params)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneo4j\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Neo4jError\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 467\u001b[0m     data, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_driver\u001b[38;5;241m.\u001b[39mexecute_query(\n\u001b[0;32m    468\u001b[0m         Query(text\u001b[38;5;241m=\u001b[39mquery, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout),\n\u001b[0;32m    469\u001b[0m         database_\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_database,\n\u001b[0;32m    470\u001b[0m         parameters_\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    471\u001b[0m     )\n\u001b[0;32m    472\u001b[0m     json_data \u001b[38;5;241m=\u001b[39m [r\u001b[38;5;241m.\u001b[39mdata() \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msanitize:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\neo4j\\_sync\\driver.py:978\u001b[0m, in \u001b[0;36mDriver.execute_query\u001b[1;34m(self, query_, parameters_, routing_, database_, impersonated_user_, bookmark_manager_, auth_, result_transformer_, **kwargs)\u001b[0m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    975\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid routing control value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrouting_\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    976\u001b[0m     )\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m session\u001b[38;5;241m.\u001b[39m_pipelined_begin:\n\u001b[1;32m--> 978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39m_run_transaction(\n\u001b[0;32m    979\u001b[0m         access_mode,\n\u001b[0;32m    980\u001b[0m         TelemetryAPI\u001b[38;5;241m.\u001b[39mDRIVER,\n\u001b[0;32m    981\u001b[0m         work,\n\u001b[0;32m    982\u001b[0m         (query_str, parameters, result_transformer_),\n\u001b[0;32m    983\u001b[0m         {},\n\u001b[0;32m    984\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:588\u001b[0m, in \u001b[0;36mSession._run_transaction\u001b[1;34m(self, access_mode, api, transaction_function, args, kwargs)\u001b[0m\n\u001b[0;32m    586\u001b[0m tx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transaction\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 588\u001b[0m     result \u001b[38;5;241m=\u001b[39m transaction_function(tx, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mCancelledError:\n\u001b[0;32m    590\u001b[0m     \u001b[38;5;66;03m# if cancellation callback has not been called yet:\u001b[39;00m\n\u001b[0;32m    591\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transaction \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\neo4j\\_work\\query.py:144\u001b[0m, in \u001b[0;36munit_of_work.<locals>.wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\neo4j\\_sync\\driver.py:1314\u001b[0m, in \u001b[0;36m_work\u001b[1;34m(tx, query, parameters, transformer)\u001b[0m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_work\u001b[39m(\n\u001b[0;32m   1309\u001b[0m     tx: ManagedTransaction,\n\u001b[0;32m   1310\u001b[0m     query: te\u001b[38;5;241m.\u001b[39mLiteralString,\n\u001b[0;32m   1311\u001b[0m     parameters: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, t\u001b[38;5;241m.\u001b[39mAny],\n\u001b[0;32m   1312\u001b[0m     transformer: t\u001b[38;5;241m.\u001b[39mCallable[[Result], t\u001b[38;5;241m.\u001b[39mUnion[_T]],\n\u001b[0;32m   1313\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _T:\n\u001b[1;32m-> 1314\u001b[0m     res \u001b[38;5;241m=\u001b[39m tx\u001b[38;5;241m.\u001b[39mrun(query, parameters)\n\u001b[0;32m   1315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transformer(res)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\neo4j\\_sync\\work\\transaction.py:206\u001b[0m, in \u001b[0;36mTransactionBase.run\u001b[1;34m(self, query, parameters, **kwparameters)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[0;32m    205\u001b[0m parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(parameters \u001b[38;5;129;01mor\u001b[39;00m {}, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwparameters)\n\u001b[1;32m--> 206\u001b[0m result\u001b[38;5;241m.\u001b[39m_tx_ready_run(query, parameters)\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\neo4j\\_sync\\work\\result.py:177\u001b[0m, in \u001b[0;36mResult._tx_ready_run\u001b[1;34m(self, query, parameters)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tx_ready_run\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, parameters):\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# BEGIN+RUN does not carry any extra on the RUN message.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;66;03m# BEGIN {extra}\u001b[39;00m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;66;03m# RUN \"query\" {parameters} {extra}\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(query, parameters, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\neo4j\\_sync\\work\\result.py:236\u001b[0m, in \u001b[0;36mResult._run\u001b[1;34m(self, query, parameters, db, imp_user, access_mode, bookmarks, notifications_min_severity, notifications_disabled_classifications)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pull()\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39msend_all()\n\u001b[1;32m--> 236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attach()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\neo4j\\_sync\\work\\result.py:430\u001b[0m, in \u001b[0;36mResult._attach\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exhausted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m--> 430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mfetch_message()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py:193\u001b[0m, in \u001b[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 193\u001b[0m         func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39miscoroutinefunction(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__on_error)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py:863\u001b[0m, in \u001b[0;36mBolt.fetch_message\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;66;03m# Receive exactly one message\u001b[39;00m\n\u001b[0;32m    860\u001b[0m tag, fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minbox\u001b[38;5;241m.\u001b[39mpop(\n\u001b[0;32m    861\u001b[0m     hydration_hooks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponses[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mhydration_hooks\n\u001b[0;32m    862\u001b[0m )\n\u001b[1;32m--> 863\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_message(tag, fields)\n\u001b[0;32m    864\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midle_since \u001b[38;5;241m=\u001b[39m monotonic()\n\u001b[0;32m    865\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt5.py:1208\u001b[0m, in \u001b[0;36mBolt5x7._process_message\u001b[1;34m(self, tag, fields)\u001b[0m\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enrich_error_diagnostic_record(summary_metadata)\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1208\u001b[0m     response\u001b[38;5;241m.\u001b[39mon_failure(summary_metadata \u001b[38;5;129;01mor\u001b[39;00m {})\n\u001b[0;32m   1209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ServiceUnavailable, DatabaseUnavailable):\n\u001b[0;32m   1210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py:263\u001b[0m, in \u001b[0;36mResponse.on_failure\u001b[1;34m(self, metadata)\u001b[0m\n\u001b[0;32m    261\u001b[0m handler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandlers\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    262\u001b[0m Util\u001b[38;5;241m.\u001b[39mcallback(handler)\n\u001b[1;32m--> 263\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hydrate_error(metadata)\n",
      "\u001b[1;31mCypherSyntaxError\u001b[0m: {code: Neo.ClientError.Statement.SyntaxError} {message: Variable `tp` not defined (line 7, column 15 (offset: 236))\r\n\"  AND toLower(tp.name) STARTS WITH \"spring\"\"\r\n               ^}"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load questions\n",
    "df = pd.read_excel(\"question2_final.xlsx\")\n",
    "\n",
    "# Add model answers\n",
    "df[\"Cypher Answer\"] = df[\"Question\"].apply(lambda x: get_query(x))\n",
    "\n",
    "# Save results\n",
    "df.to_excel(\"qa2_results.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d1bbe92-7702-45a5-b532-747131852a79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Cypher:\n",
      " MATCH (s:Subject)\n",
      "WHERE NOT EXISTS {\n",
      "  MATCH (s)-[:REQUIRES]->(preqsub:Subject)\n",
      "}\n",
      "RETURN DISTINCT s.code\n",
      "['COMP7024']\n",
      "['MATH7016']\n",
      "['COMP7003']\n",
      "['COMP7006']\n",
      "['COMP7023']\n",
      "['INFO7016']\n",
      "['COMP7025']\n",
      "Answered in 34.48 seconds\n",
      "Generated Cypher:\n",
      " MATCH (s:Subject)\n",
      "WHERE NOT EXISTS {\n",
      "  MATCH (s)-[:REQUIRES]->(preqsub:Subject)\n",
      "  WHERE s.code IN ['MATH7016', 'COMP7024', 'COMP7003', 'COMP7016']\n",
      "}\n",
      "AND NOT EXISTS {\n",
      "  MATCH (s)-[:REQUIRES]->(preqsub:Subject)\n",
      "  WHERE preqsub.code IN ['MATH7016', 'COMP7024', 'COMP7003', 'COMP7016']\n",
      "}\n",
      "AND EXISTS {\n",
      "  MATCH (s)-[:OFFERED_IN]->(tp:TeachingPeriod)\n",
      "  WHERE toLower(tp.name) STARTS WITH \"spring\"\n",
      "}\n",
      "RETURN DISTINCT s.code, s.name\n",
      "['COMP7024', 'Programming for Data Science']\n",
      "['MATH7016', 'The Nature of Data']\n",
      "['COMP7006', 'Data Science']\n",
      "['COMP7023', 'Predictive Analytics']\n",
      "['INFO7016', 'Postgraduate Project A']\n",
      "['INFO7017', 'Postgraduate Project B']\n",
      "Answered in 106.27 seconds\n",
      "Generated Cypher:\n",
      " MATCH (s:Subject)\n",
      "WHERE NOT EXISTS {\n",
      "  MATCH (s)-[:REQUIRES]->(preqsub:Subject)\n",
      "  WHERE s.code IN ['MATH7002', 'COMP7006', 'COMP7023']\n",
      "}\n",
      "AND EXISTS {\n",
      "  MATCH (s)-[:OFFERED_IN]->(tp:TeachingPeriod)\n",
      "  WHERE toLower(tp.name) STARTS WITH \"autumn\"\n",
      "}\n",
      "RETURN DISTINCT s.code, s.name\n",
      "['COMP7024', 'Programming for Data Science']\n",
      "['MATH7016', 'The Nature of Data']\n",
      "['COMP7003', 'Big Data']\n",
      "['COMP7016', 'Visualisation']\n",
      "['INFO7016', 'Postgraduate Project A']\n",
      "['COMP7025', 'Social Media Intelligence']\n",
      "['INFO7017', 'Postgraduate Project B']\n",
      "['MATH7017', 'Probablistic Graphical Models']\n",
      "Answered in 72.26 seconds\n",
      "Generated Cypher:\n",
      " MATCH (s:Subject)\n",
      "WHERE NOT EXISTS {\n",
      "  MATCH (s)-[:REQUIRES]->(preqsub:Subject)\n",
      "  WITH preqsub\n",
      "  MATCH (preqsub)\n",
      "  WHERE s.code IN ['MATH7002', 'COMP7006', 'COMP7023', 'MATH7016', 'COMP7003', 'COMP7016']\n",
      "}\n",
      "AND EXISTS {\n",
      "  MATCH (s)-[:OFFERED_IN]->(tp:TeachingPeriod)\n",
      "  WHERE toLower(tp.name) STARTS WITH \"spring\"\n",
      "}\n",
      "RETURN DISTINCT s.code, s.name\n",
      "['COMP7024', 'Programming for Data Science']\n",
      "['MATH7016', 'The Nature of Data']\n",
      "['COMP7006', 'Data Science']\n",
      "['COMP7023', 'Predictive Analytics']\n",
      "['INFO7016', 'Postgraduate Project A']\n",
      "['INFO7001', 'Advanced Machine Learning']\n",
      "['INFO7017', 'Postgraduate Project B']\n",
      "Answered in 98.22 seconds\n",
      "Generated Cypher:\n",
      " MATCH (s:Subject)-[:HAS_OUTCOME]->(o:Outcome)\n",
      "WHERE toLower(o.description) CONTAINS \"machine learning\"\n",
      "RETURN DISTINCT s.code, s.name\n",
      "['COMP7006', 'Data Science']\n",
      "['INFO7001', 'Advanced Machine Learning']\n",
      "Answered in 35.73 seconds\n",
      "Generated Cypher:\n",
      " MATCH (s:Subject)-[:HAS_OUTCOME]->(o:Outcome)\n",
      "WHERE toLower(o.description) CONTAINS \"project\" OR toLower(o.description) CONTAINS \"major project\"\n",
      "RETURN DISTINCT s.code, s.name\n",
      "['INFO7017', 'Postgraduate Project B']\n",
      "Answered in 40.88 seconds\n",
      "Generated Cypher:\n",
      " MATCH (s:Subject)-[:HAS_OUTCOME]->(o:Outcome)\n",
      "WHERE toLower(o.description) CONTAINS \"python programming\"\n",
      "RETURN DISTINCT s.code, s.name\n",
      "Answered in 32.99 seconds\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'answer' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion2_final.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Add model answers\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Answer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: get_query(x))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Save results\u001b[39;00m\n\u001b[0;32m     10\u001b[0m df\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqa2_results.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4919\u001b[0m         func,\n\u001b[0;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[38], line 7\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion2_final.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Add model answers\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Answer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: get_query(x))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Save results\u001b[39;00m\n\u001b[0;32m     10\u001b[0m df\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqa2_results.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[36], line 18\u001b[0m, in \u001b[0;36mget_query\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(answer)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m answer\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'answer' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load questions\n",
    "df = pd.read_excel(\"question2_final.xlsx\")\n",
    "\n",
    "# Add model answers\n",
    "df[\"Model Answer\"] = df[\"Question\"].apply(lambda x: get_query(x))\n",
    "\n",
    "# Save results\n",
    "df.to_excel(\"qa2_results.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f49c14fb-30de-4c50-b7cb-24e4bef7f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with driver.session() as session:\n",
    "#     result = session.run(\"\"\"\n",
    "#     MATCH (s:Subject)-[:COORDINATED_BY]->(c:Coordinator),\n",
    "#           (s)-[:OFFERED_IN]->(t:TeachingPeriod),\n",
    "#           (s)-[:HAS_OUTCOME]->(o:Outcome)\n",
    "#     RETURN s.name AS subject, c.name AS coordinator,\n",
    "#            collect(DISTINCT t.name) AS periods,\n",
    "#            collect(DISTINCT o.description) AS outcomes\n",
    "#     LIMIT 5\n",
    "#     \"\"\")\n",
    "#     for record in result:\n",
    "#         print(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "241d229f-5adf-44c4-9c89-76767ec37322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "driver = GraphDatabase.driver(\"neo4j://127.0.0.1:7687\", auth=(\"neo4j\",\"datvip01\"))\n",
    "driver.verify_connectivity()\n",
    "\n",
    "with driver.session() as s:\n",
    "    s.run(\"MATCH (n) DETACH DELETE n\")  # optional clean slate while prototyping\n",
    "    # s.run(\"CREATE CONSTRAINT subj_code      IF NOT EXISTS FOR (s:Subject)        REQUIRE s.code IS UNIQUE\")\n",
    "    # s.run(\"CREATE CONSTRAINT coord_name     IF NOT EXISTS FOR (c:Coordinator)    REQUIRE c.name IS UNIQUE\")\n",
    "    # s.run(\"CREATE CONSTRAINT period_name    IF NOT EXISTS FOR (p:TeachingPeriod) REQUIRE p.name IS UNIQUE\")\n",
    "    # s.run(\"CREATE CONSTRAINT outcome_desc   IF NOT EXISTS FOR (o:Outcome)        REQUIRE o.description IS UNIQUE\")\n",
    "    # s.run(\"CREATE CONSTRAINT topic_name     IF NOT EXISTS FOR (t:Topic)          REQUIRE t.name IS UNIQUE\")\n",
    "    # s.run(\"CREATE CONSTRAINT know_name      IF NOT EXISTS FOR (k:AssumedKnowledge) REQUIRE k.name IS UNIQUE\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
